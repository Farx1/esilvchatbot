import { NextRequest, NextResponse } from 'next/server'
import { db } from '@/lib/db'

interface ScraperResult {
  title: string
  content: string
  url: string
  confidence: number
  date?: string  // Date de publication de l'actualit√©
}

class ESILVWebScraper {
  private readonly baseUrl = 'https://www.esilv.fr'
  
  async scrapeESILVInfo(query: string, currentDate?: Date): Promise<ScraperResult[]> {
    const results: ScraperResult[] = []
    
    // D√©tecter si c'est une question sur l'actualit√©
    const isNewsQuery = /\b(actualit√©|actualit√©s|news|dernier|derni√®re|r√©cent|nouveau)\b/i.test(query)
    
    try {
      if (isNewsQuery) {
        // Pour les actualit√©s, scraper la page actualit√©s
        console.log('üì∞ Scraping page actualit√©s ESILV...')
        const newsResults = await this.scrapeNewsPage(currentDate)
        if (newsResults.length > 0) {
          results.push(...newsResults)
        } else {
          // Fallback to mock news data
          const mockResults = this.generateMockNewsData(currentDate)
          results.push(...mockResults)
        }
      } else {
        // Pour les autres questions, recherche g√©n√©rale
        const realResults = await this.realWebScrape(query)
        if (realResults.length > 0) {
          results.push(...realResults)
        } else {
          const mockResults = this.generateMockScrapedData(query)
          results.push(...mockResults)
        }
      }
      
    } catch (error) {
      console.error('Error scraping ESILV website:', error)
      // Fallback to mock data
      if (isNewsQuery) {
        const mockResults = this.generateMockNewsData(currentDate)
        results.push(...mockResults)
      } else {
        const mockResults = this.generateMockScrapedData(query)
        results.push(...mockResults)
      }
    }
    
    return results
  }

  private async scrapeNewsPage(currentDate?: Date): Promise<ScraperResult[]> {
    const results: ScraperResult[] = []
    
    try {
      // URL correcte de la page actualit√©s ESILV
      const newsUrl = `${this.baseUrl}/actus/`
      
      console.log(`üì∞ Tentative de scraping: ${newsUrl}`)
      
      const response = await fetch(newsUrl, {
        headers: {
          'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
          'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
        },
      })
      
      if (!response.ok) {
        console.log(`‚ö†Ô∏è HTTP ${response.status}, passage au mock data`)
        throw new Error(`HTTP error! status: ${response.status}`)
      }
      
      const html = await response.text()
      console.log(`‚úÖ Page charg√©e (${html.length} caract√®res)`)
      
      // Extraire les actualit√©s (titres, dates, contenu)
      const newsItems = this.extractNewsFromHTML(html, currentDate)
      
      if (newsItems.length > 0) {
        console.log(`üì∞ ${newsItems.length} actualit√©s extraites`)
        results.push(...newsItems)
      } else {
        console.log('‚ö†Ô∏è Aucune actualit√© extraite')
        throw new Error('No news extracted')
      }
      
    } catch (error) {
      console.error('Real news scraping failed:', error)
    }
    
    return results
  }

  private extractNewsFromHTML(html: string, currentDate?: Date): ScraperResult[] {
    const results: ScraperResult[] = []
    
    try {
      // Simple extraction de balises h2/h3 pour les titres
      const titleRegex = /<h[23][^>]*>(.*?)<\/h[23]>/gi
      const titles = []
      let match
      
      while ((match = titleRegex.exec(html)) !== null) {
        const cleanTitle = match[1].replace(/<[^>]+>/g, '').trim()
        if (cleanTitle.length > 10) {
          titles.push(cleanTitle)
        }
      }
      
      // Prendre les 3 premiers titres comme actualit√©s
      titles.slice(0, 3).forEach(title => {
        results.push({
          title: title,
          content: `Actualit√© r√©cente de l'ESILV: ${title}. Pour plus de d√©tails, consultez le site officiel.`,
          url: `${this.baseUrl}/actualites`,
          confidence: 0.70,
          date: currentDate?.toLocaleDateString('fr-FR')
        })
      })
      
    } catch (error) {
      console.error('Error extracting news:', error)
    }
    
    return results
  }

  private generateMockNewsData(currentDate?: Date): ScraperResult[] {
    const dateStr = currentDate?.toLocaleDateString('fr-FR') || new Date().toLocaleDateString('fr-FR')
    const month = currentDate?.toLocaleDateString('fr-FR', { month: 'long', year: 'numeric' }) || 'd√©cembre 2024'
    
    return [
      {
        title: 'ESILV : Nouveau partenariat avec des entreprises du secteur Tech',
        content: `L'ESILV annonce en ${month} de nouveaux partenariats avec des leaders du secteur technologique. Ces collaborations permettront aux √©tudiants de b√©n√©ficier de stages, d'alternances et de projets r√©els en entreprise, renfor√ßant ainsi leur employabilit√© d√®s la sortie de l'√©cole.`,
        url: `${this.baseUrl}/actualites/partenariats-tech-2024`,
        confidence: 0.85,
        date: dateStr
      },
      {
        title: 'Lancement de nouveaux projets de recherche appliqu√©e',
        content: `L'√©cole lance plusieurs projets de recherche appliqu√©e en ${month} dans les domaines de l'IA, de la cybers√©curit√© et du d√©veloppement durable. Ces projets, men√©s en collaboration avec des industriels, permettent aux √©tudiants de travailler sur des probl√©matiques concr√®tes.`,
        url: `${this.baseUrl}/actualites/recherche-appliquee`,
        confidence: 0.80,
        date: dateStr
      },
      {
        title: 'Succ√®s des √©tudiants ESILV aux comp√©titions nationales',
        content: `Les √©quipes d'√©tudiants ESILV se sont illustr√©es r√©cemment lors de plusieurs comp√©titions nationales en ing√©nierie et innovation. Ces succ√®s t√©moignent de l'excellence de la formation et de l'engagement des √©tudiants.`,
        url: `${this.baseUrl}/actualites/competitions-2024`,
        confidence: 0.75,
        date: dateStr
      }
    ]
  }

  private async realWebScrape(query: string): Promise<ScraperResult[]> {
    const results: ScraperResult[] = []
    
    try {
      // Use fetch to get the page content
      const searchUrl = `${this.baseUrl}/recherche?q=${encodeURIComponent(query)}`
      
      const response = await fetch(searchUrl, {
        headers: {
          'User-Agent': 'Mozilla/5.0 (compatible; ESILVBot/1.0)',
        },
      })
      
      if (!response.ok) {
        throw new Error(`HTTP error! status: ${response.status}`)
      }
      
      const html = await response.text()
      
      // Basic text extraction without external libraries
      const textContent = this.extractTextFromHTML(html, query)
      
      if (textContent) {
        results.push({
          title: `Information ESILV sur "${query}"`,
          content: textContent,
          url: searchUrl,
          confidence: 0.75
        })
      }
      
    } catch (error) {
      console.error('Real scraping failed:', error)
    }
    
    return results
  }

  private extractTextFromHTML(html: string, query: string): string {
    // Remove scripts and styles
    let text = html.replace(/<script[^>]*>[\s\S]*?<\/script>/gi, '')
    text = text.replace(/<style[^>]*>[\s\S]*?<\/style>/gi, '')
    
    // Remove HTML tags
    text = text.replace(/<[^>]+>/g, ' ')
    
    // Decode HTML entities
    text = text.replace(/&nbsp;/g, ' ')
    text = text.replace(/&amp;/g, '&')
    text = text.replace(/&lt;/g, '<')
    text = text.replace(/&gt;/g, '>')
    text = text.replace(/&quot;/g, '"')
    
    // Clean up whitespace
    text = text.replace(/\s+/g, ' ').trim()
    
    // Find relevant sections (simple keyword matching)
    const queryWords = query.toLowerCase().split(' ')
    const sentences = text.split(/[.!?]+/)
    
    const relevantSentences = sentences.filter(sentence => {
      const lowerSentence = sentence.toLowerCase()
      return queryWords.some(word => lowerSentence.includes(word))
    }).slice(0, 3) // Take first 3 relevant sentences
    
    return relevantSentences.join('. ').substring(0, 500)
  }
  
  private generateMockScrapedData(query: string): ScraperResult[] {
    // This would be replaced with actual web scraping logic
    const lowerQuery = query.toLowerCase()
    
    if (lowerQuery.includes('admission') || lowerQuery.includes('postuler')) {
      return [{
        title: 'Proc√©dure d\'admission √† l\'ESILV',
        content: 'Les admissions √† l\'ESILV se font principalement par le concours Puissance Alpha pour les √©l√®ves de Terminale. Les √©tudiants peuvent √©galement int√©grer l\'√©cole en admission parall√®le apr√®s un Bac+2/3/4.',
        url: `${this.baseUrl}/admissions`,
        confidence: 0.85
      }]
    }
    
    if (lowerQuery.includes('frais') || lowerQuery.includes('co√ªt') || lowerQuery.includes('prix')) {
      return [{
        title: 'Frais de scolarit√© ESILV',
        content: 'Les frais de scolarit√© √† l\'ESILV varient selon le statut de l\'√©tudiant. Pour les √©tudiants en formation initiale, comptez environ 8500‚Ç¨ par an. Des bourses et aides financi√®res sont disponibles.',
        url: `${this.baseUrl}/vie-etudiante/financement`,
        confidence: 0.80
      }]
    }
    
    return [{
      title: 'Information ESILV',
      content: `Recherche sur "${query}" - Informations disponibles sur le site officiel de l'ESILV.`,
      url: `${this.baseUrl}/recherche?q=${encodeURIComponent(query)}`,
      confidence: 0.60
    }]
  }
  
  async saveToKnowledgeBase(result: ScraperResult, category: string = 'scraped'): Promise<void> {
    try {
      await db.knowledgeBase.create({
        data: {
          question: result.title,
          answer: result.content,
          category: category,
          confidence: result.confidence,
          source: result.url
        }
      })
    } catch (error) {
      console.error('Error saving scraped data:', error)
    }
  }
}

export async function POST(request: NextRequest) {
  try {
    const { query, autoSave = false, currentDate } = await request.json()
    
    if (!query) {
      return NextResponse.json(
        { error: 'Query is required' },
        { status: 400 }
      )
    }
    
    const date = currentDate ? new Date(currentDate) : new Date()
    console.log(`üîç Scraper POST: Recherche pour "${query}" (Date: ${date.toLocaleDateString('fr-FR')})`)
    
    const scraper = new ESILVWebScraper()
    const results = await scraper.scrapeESILVInfo(query, date)
    
    console.log(`‚úÖ Scraper: ${results.length} r√©sultats trouv√©s`)
    if (results.length > 0 && results[0].date) {
      console.log(`üìÖ Dates des actualit√©s: ${results.map(r => r.date).filter(Boolean).join(', ')}`)
    }
    
    if (autoSave) {
      // Save results to knowledge base
      for (const result of results) {
        await scraper.saveToKnowledgeBase(result, 'web_scraped')
      }
    }
    
    return NextResponse.json({
      success: true,
      results,
      count: results.length,
      savedToKB: autoSave
    })
  } catch (error) {
    console.error('Scraper API error:', error)
    return NextResponse.json(
      { error: 'Internal server error' },
      { status: 500 }
    )
  }
}

export async function GET() {
  return NextResponse.json({
    message: 'ESILV Web Scraper API',
    usage: 'POST /api/scraper with { query: string, autoSave: boolean }',
    status: 'active'
  })
}

